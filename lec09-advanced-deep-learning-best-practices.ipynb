{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lec09-advanced-deep-learning-best-practices.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Gijt2H-HVrS_"},"source":["## 7.1 Going beyond the Sequential model"]},{"cell_type":"markdown","source":["technical한 내용들 설명"],"metadata":{"id":"MDmC1stFH0D-"}},{"cell_type":"markdown","metadata":{"id":"F5NtMMymWBoM"},"source":["* Until now, all neural networks introduced before have been implemented using the `Sequential` model.\n","\n","  <img src=\"https://drive.google.com/uc?id=1ZXI42nVA8DN40JG4QsOvU6IFBMgHfNJK\" width=\"300\">\n","\n","* Some networks require:\n","  * several independent inputs,\n","  * multiple outputs,\n","  * internal branching between layers that makes them look like graphs of layers rather than linear stacks of layers.\n","  \n","* *Multimodal* inputs\n","  * data coming from different input sources, processing each type of data using different kinds of neural layers\n","  * Ex. a deep learning model to predict the most likely market price of a second-hand piece of clothing using the following inputs:\n","    * user-provided metadata: brand, age, etc.\n","    * user-provided text description\n","    * a picture of the item\n","    \n","      <img src=\"https://drive.google.com/uc?id=1ZYV_1OqkoiW5-xjECBaqcFQvLZVhhlRK\" width=\"700\">\n","    \n","* *Multiple* targets\n","  * predict multiple target attributes of input data\n","  * Ex. Given the text of a novel, classify it by genre and predict the approximate date it was wrtitten simoutaneously.\n","  \n","   <img src=\"https://drive.google.com/uc?id=1ZcQzkbgoKVSu7FbTQsJhIy2yN6nYAT9P\" width=\"400\">\n","  \n","* Networks structured as directed acyclic graphs\n","  * The Inception family of networks having *Inception modules*\n","  \n","    <img src=\"https://drive.google.com/uc?id=1ZeBw9KykV8u7bgyitHPvho9-SfiSWGgQ\" width=\"500\">\n","  \n","  * The residual network having residual connections\n","  \n","    <img src=\"https://drive.google.com/uc?id=1ZqD1rYEg3wd6XA8LjRZo-JYsbIgQ1ro9\" width=\"500\">\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JI4QQgaUIBbx"},"source":["### The functional API of *keras*"]},{"cell_type":"markdown","metadata":{"id":"K9MoaMNVIcoF"},"source":["* We can use layers as *functions* that take tensors and return tensors (hence, the name *functional* API)."]},{"cell_type":"code","metadata":{"id":"WhYjOYUBIrlb"},"source":["from tensorflow.keras import Input, layers\n","\n","input_tensor = Input(shape=(32,))\n","dense = layers.Dense(32, activation='relu')\n","output_tensor = dense(input_tensor)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6aEIux4TI_50","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651796769240,"user_tz":-540,"elapsed":8,"user":{"displayName":"Sangheum Hwang","userId":"12292317320178717925"}},"outputId":"87b8317f-d5eb-49f9-b60c-5dbe3e32496d"},"source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras import layers\n","from tensorflow.keras import Input\n","\n","seq_model = Sequential()\n","seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n","seq_model.add(layers.Dense(32, activation='relu'))\n","seq_model.add(layers.Dense(10, activation='softmax'))\n","\n","input_tensor = Input(shape=(64,))\n","x = layers.Dense(32, activation='relu')(input_tensor)\n","x = layers.Dense(32, activation='relu')(x)\n","output_tensor = layers.Dense(10, activation='softmax')(x)\n","\n","model = Model(input_tensor, output_tensor) # need only an input and target tensor\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 64)]              0         \n","                                                                 \n"," dense_4 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_5 (Dense)             (None, 32)                1056      \n","                                                                 \n"," dense_6 (Dense)             (None, 10)                330       \n","                                                                 \n","=================================================================\n","Total params: 3,466\n","Trainable params: 3,466\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"hCTK67NtJrN-","colab":{"base_uri":"https://localhost:8080/","height":351},"executionInfo":{"status":"error","timestamp":1651796776677,"user_tz":-540,"elapsed":471,"user":{"displayName":"Sangheum Hwang","userId":"12292317320178717925"}},"outputId":"bc466313-51c5-4844-cf74-933d222abfa7"},"source":["unrelated_input = Input(shape=(64,))\n","bad_model = Model(unrelated_input, output_tensor)\n","# 위에서는 x값들이 다 연결되어있는데 여기서는 연결이 안돼이있기때문에 graph disconnected라 표현되는거이다."],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-06946d3b500e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0munrelated_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbad_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munrelated_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m                   for t in tf.nest.flatten(inputs)]):\n\u001b[1;32m    145\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0;32m--> 230\u001b[0;31m         self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             raise ValueError(\n\u001b[0;32m-> 1037\u001b[0;31m                 \u001b[0;34mf'Graph disconnected: cannot obtain value for tensor {x} '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m                 \u001b[0;34mf'at layer \"{layer.name}\". The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m                 f'were accessed without issue: {layers_with_complete_input}')\n","\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\") at layer \"dense_4\". The following previous layers were accessed without issue: []"]}]},{"cell_type":"code","metadata":{"id":"5pF9PWbWQepw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651796784254,"user_tz":-540,"elapsed":3882,"user":{"displayName":"Sangheum Hwang","userId":"12292317320178717925"}},"outputId":"36a1d091-f0c6-47f1-e235-c4f5857930b9"},"source":["model.compile(optimizer='rmsprop',\n","              loss='categorical_crossentropy')\n","\n","import numpy as np\n","x_train = np.random.random((1000,64))\n","y_train = np.random.random((1000,10))\n","\n","model.fit(x_train, y_train, epochs=10, batch_size=128)\n","\n","score = model.evaluate(x_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","8/8 [==============================] - 3s 4ms/step - loss: 11.7837\n","Epoch 2/10\n","8/8 [==============================] - 0s 4ms/step - loss: 12.0685\n","Epoch 3/10\n","8/8 [==============================] - 0s 4ms/step - loss: 12.5121\n","Epoch 4/10\n","8/8 [==============================] - 0s 4ms/step - loss: 13.4361\n","Epoch 5/10\n","8/8 [==============================] - 0s 4ms/step - loss: 15.3171\n","Epoch 6/10\n","8/8 [==============================] - 0s 4ms/step - loss: 17.8998\n","Epoch 7/10\n","8/8 [==============================] - 0s 4ms/step - loss: 20.8421\n","Epoch 8/10\n","8/8 [==============================] - 0s 4ms/step - loss: 24.6523\n","Epoch 9/10\n","8/8 [==============================] - 0s 4ms/step - loss: 29.2564\n","Epoch 10/10\n","8/8 [==============================] - 0s 4ms/step - loss: 34.5480\n","32/32 [==============================] - 0s 4ms/step - loss: 37.5988\n"]}]},{"cell_type":"markdown","metadata":{"id":"naEpfWu7Q-kH"},"source":["### Multi-input models"]},{"cell_type":"markdown","metadata":{"id":"4oJtMk1yRgHh"},"source":["* Such models at some point merge their different input branches using a layer that can combine several tensors:\n","  * adding them, concatenating them, etc.\n","  * *keras.layers.add*, *keras.layers.concatenate*\n","  \n","* A question-answering model\n","  * A typical QnA model has two inputs: \n","    * a natural-language question 질문(문제)\n","    * a text snippet 지문\n","  * The model then produces an answer.\n","  \n","  <img src=\"https://drive.google.com/uc?id=1ZqZTfHEJIBqhXXPmcJ6DMCW20UfL9zQG\" width=\"400\">\n","\n","  \n","  "]},{"cell_type":"code","metadata":{"id":"On7Gq_WJSu5f"},"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras import layers\n","from tensorflow.keras import Input\n","\n","text_vocabulary_size = 10000\n","question_vocabulary_size = 10000\n","answer_vocabulary_size = 500\n","\n","text_input = Input(shape=(None,), dtype='int32', name='text')\n","embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input)\n","encoded_text = layers.LSTM(32)(embedded_text) # ,~~32)가 될것이고\n","\n","question_input = Input(shape=(None,), dtype='int32', name='question')\n","embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)\n","encoded_question = layers.LSTM(16)(embedded_question) # ,~~16)이 될것이고\n","\n","concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1) #여기는 ~~,32+16)으로 되는 과정이다.\n","\n","answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n","\n","model = Model([text_input, question_input], answer)\n","model.compile(optimizer='rmsprop',\n","              loss='categorical_crossentropy',\n","              metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b5-KG1YXT5P2"},"source":["* Then, how to train this two-input model?\n","  * You can feed the model a list of Numpy arrays as inputs.\n","  * Or, you can feed it a dictionary that maps input names to Numpy arrays.<br>\n","  데이터input이 질문, 지문 두개가 있는데 어케 하는지도 알아보자"]},{"cell_type":"code","metadata":{"id":"khIj4Um2UG4S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651796817886,"user_tz":-540,"elapsed":15294,"user":{"displayName":"Sangheum Hwang","userId":"12292317320178717925"}},"outputId":"a74f05ac-22cb-4522-9ef6-96101734b5b4"},"source":["import numpy as np\n","\n","num_samples = 1000\n","max_length = 100\n","\n","text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n","question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n","\n","label_index = np.random.randint(0,answer_vocabulary_size, size=(num_samples,))\n","answer = np.zeros((num_samples,answer_vocabulary_size))\n","answer[np.arange(num_samples), label_index] = 1\n","\n","# There are two options.\n","#model.fit([text, question], answer, epochs=10, batch_size=128)\n","model.fit({'text':text, 'question':question}, answer, epochs=10, batch_size=128)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","8/8 [==============================] - 7s 46ms/step - loss: 6.2149 - acc: 0.0000e+00\n","Epoch 2/10\n","8/8 [==============================] - 0s 44ms/step - loss: 6.1973 - acc: 0.0420\n","Epoch 3/10\n","8/8 [==============================] - 0s 44ms/step - loss: 6.1489 - acc: 0.0090\n","Epoch 4/10\n","8/8 [==============================] - 0s 44ms/step - loss: 6.0787 - acc: 0.0070\n","Epoch 5/10\n","8/8 [==============================] - 0s 42ms/step - loss: 5.9828 - acc: 0.0110\n","Epoch 6/10\n","8/8 [==============================] - 0s 43ms/step - loss: 5.8766 - acc: 0.0190\n","Epoch 7/10\n","8/8 [==============================] - 0s 44ms/step - loss: 5.7743 - acc: 0.0350\n","Epoch 8/10\n","8/8 [==============================] - 0s 43ms/step - loss: 5.7065 - acc: 0.0330\n","Epoch 9/10\n","8/8 [==============================] - 0s 44ms/step - loss: 5.6380 - acc: 0.0400\n","Epoch 10/10\n","8/8 [==============================] - 0s 44ms/step - loss: 5.5696 - acc: 0.0430\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0bd591f8d0>"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"S0079-iyUoz1"},"source":["### Multi-output models"]},{"cell_type":"code","metadata":{"id":"jlT8HDKhU0cq"},"source":["from tensorflow.keras import layers\n","from tensorflow.keras import Input\n","from tensorflow.keras.models import Model\n","\n","vocabulary_size = 50000\n","num_income_groups = 10\n","\n","posts_input = Input(shape=(None,), dtype='int32', name='posts')\n","embedded_posts = layers.Embedding(vocabulary_size, 256)(posts_input)\n","x = layers.Conv1D(128, 5, activation='relu')(embedded_posts) \n","x = layers.MaxPooling1D(5)(x) \n","x = layers.Conv1D(256, 5, activation='relu')(x) \n","x = layers.Conv1D(256, 5, activation='relu')(x) \n","x = layers.MaxPooling1D(5)(x) \n","x = layers.Conv1D(256, 5, activation='relu')(x) \n","x = layers.Conv1D(256, 5, activation='relu')(x) \n","x = layers.GlobalMaxPooling1D()(x)\n","x = layers.Dense(128, activation='relu')(x)\n","\n","age_prediction = layers.Dense(1, name='age')(x)\n","income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n","gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n","\n","model = Model(posts_input,\n","              [age_prediction, income_prediction, gender_prediction])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2njxLuy6VhGP"},"source":["# Different loss functions for different tasks\n","# Again, there are two options for that.\n","\n","#model.compile(optimizer='rmsprop',\n","#              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n","model.compile(optimizer='rmsprop',\n","              loss={'age': 'mse',\n","                    'income': 'categorical_crossentropy',\n","                    'gender': 'binary_crossentropy'})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5kX61rlwWZUO"},"source":["* Note that very imbalanced loss contributions will cause the model representations to be optimized for the task with the largest individual loss.\n","  * For example, the MSE loss typically takes a value around 3-5, whereas the binary CE loss can be as low as 0.1.\n","  * To balance the contribution of the different losses, you can assign a weight to loss."]},{"cell_type":"code","metadata":{"id":"pXx9qox2Wupm"},"source":["#model.compile(optimizer='rmsprop',\n","#              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n","#              loss_weights=[0.25, 1., 10.])\n","\n","model.compile(optimizer='rmsprop',\n","              loss={'age': 'mse', \n","                    'income': 'categorical_crossentropy', \n","                    'gender': 'binary_crossentropy'}, \n","              loss_weights={'age': 0.25, \n","                            'income': 1., \n","                            'gender': 10.})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zGj0BVRPXPFV"},"source":["# feeding data to a multi-output model\n","\n","model.fit(posts, [age_targets, income_targets, gender_targets],\n","          epochs=10, batch_size=64)\n","\n","model.fit(posts, {'age': age_targets,\n","                  'income': income_targets,\n","                  'gender': gender_targets},\n","          epochs=10, batch_size=64)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FdkJJ6doXijg"},"source":["### Directed acyclic graphs of layers"]},{"cell_type":"markdown","metadata":{"id":"IjnzQbrSXk-T"},"source":["* Neural networks are allowed to be arbitrary *directed acyclic graphs* of layers.\n","\n","* Several common neural network components are implemented as graphs.\n","\n","* **Inception module**\n","  * developed by Szegedy in 2013-2014.\n","  * It consists of a stack of modules that themselves look like small independent networks, split into several parallel branches.\n","  \n","    <img src=\"https://drive.google.com/uc?id=1ZrKSiDl4rLwV_4fHfjAXr9BbIFMBiI0j\" width=\"700\">"]},{"cell_type":"code","metadata":{"id":"EmPX4FK4ZEbq"},"source":["from tensorflow.keras import layers\n","from tensorflow.keras import Input\n","\n","x = Input(shape=(256, 256, 64))\n","\n","branch_a = layers.Conv2D(128, 1, activation='relu', strides=2)(x) \n","\n","branch_b = layers.Conv2D(128, 1, activation='relu')(x) \n","branch_b = layers.Conv2D(128, 3, activation='relu', strides=2, padding='same')(branch_b)\n","\n","branch_c = layers.AveragePooling2D(3, strides=2, padding='same')(x) \n","branch_c = layers.Conv2D(128, 3, activation='relu', padding='same')(branch_c)\n","\n","branch_d = layers.Conv2D(128, 1, activation='relu')(x) \n","branch_d = layers.Conv2D(128, 3, activation='relu', padding='same')(branch_d) \n","branch_d = layers.Conv2D(128, 3, activation='relu', strides=2, padding='same')(branch_d)\n","\n","output = layers.concatenate( [branch_a, branch_b, branch_c, branch_d], axis=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yPjHMLOkZ1F7"},"source":["* **Residual connections**\n","\n","  * Introduced by He et al. in late 2015.\n","  * They tackle two common problems of any large-scale deep learning model:\n","    * vanishing gradients and representational bottlenecks.\n","  * Residual connection consists of making the output of an earlier layer available as input to a later layer by creating a shortcut.\n","  * Rather than being concatenated to the later activation, the earlier output is summed with the later activation."]},{"cell_type":"code","metadata":{"id":"lRRxfbK6ahIg"},"source":["from tensorflow.keras import layers\n","\n","x = ...\n","y = layers.Conv2D(128, 3, activation='relu', padding='same')(x) \n","y = layers.Conv2D(128, 3, activation='relu', padding='same')(y) \n","y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n","\n","y = layers.add([y,x])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q1MgTCvYasF-"},"source":["# if the feature map sizes differ\n","\n","from tensorflow.keras import layers\n","\n","x = ...\n","y = layers.Conv2D(128, 3, activation='relu', padding='same')(x) \n","y = layers.Conv2D(128, 3, activation='relu', padding='same')(y) \n","y = layers.MaxPooling2D(2, strides=2)(y)\n","\n","residual = layers.Conv2D(128, 1, strides=2, padding='same')(x)\n","\n","y = layers.add([y, residual])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SRlFW4AabT6O"},"source":["### Layer weight sharing"]},{"cell_type":"markdown","metadata":{"id":"qqkMOJgwbXQ9"},"source":["* We can reuse a layer instance several times by the functional API.\n","\n","* For example, consider a model that attempts to assess the semantic similarity between two sentences.\n","  * In this setup, the two input sentences are interchangeable.\n","  * We call this a *Siamese* LSTM."]},{"cell_type":"code","metadata":{"id":"KwjZsC2qb6rZ"},"source":["from tensorflow.keras import layers \n","from tensorflow.keras import Input \n","from tensorflow.keras.models import Model\n","\n","lstm = layers.LSTM(32)\n","\n","left_input = Input(shape=(None, 128))\n","left_output = lstm(left_input) # weight를 아래랑 sharing 한다   # 만약 let_output = layers.lstem(left_input)으로 만들면 wieght가 따로놀거다\n","\n","right_input = Input(shape=(None, 128))\n","right_output = lstm(right_input)\n","\n","merged = layers.concatenate([left_output, right_output], axis=-1) \n","predictions = layers.Dense(1, activation='sigmoid')(merged)    \n","\n","model = Model([left_input, right_input], predictions) \n","model.fit([left_data, right_data], targets)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"66xkq0PHfqPC"},"source":["## 7.2 Inspecting and monitoring models: Callbacks and TensorBoard"]},{"cell_type":"markdown","metadata":{"id":"-NhxrI-5fv1q"},"source":["### Using callbacks to act on a model during training"]},{"cell_type":"markdown","metadata":{"id":"TkEgKf0Tfz3Q"},"source":["* Ex. we want to stop training when the validation loss is no longer improving.\n","\n","* A callback is an object that is passed to the model in the call to `fit` and that is called by the model at various points during training.\n","  * It has access to all the available data about the state of the model and its performance.\n","  * It can take action: interrupt training, save a model, load a different weight set, or otherwise alter the state of the model\n","  \n","* Some examples of ways using callbacks:\n","  * Model checkpointing - saving the current weights of the model at different points during training\n","  * Early stopping - interrupting training when the validation loss is no longer improving\n","  * Dynamically adjusting the value of certain parameters during training - such as the learning rate of the optimizer\n","  * Logging training and validation metrics, or visualizing the representations learned by the model as they're updated - the Keras progress bar is a callback.\n","  \n","* The list of built-in callbacks\n","  * https://keras.io/callbacks/"]},{"cell_type":"markdown","metadata":{"id":"3aBbEaA0hRtB"},"source":["* **ModelCheckpoint** and **EarlyStopping** callbacks\n","\n","  * `EarlyStopping` - interrupt training once a target metric being monitored has stopped improving for a fixed number of epochs\n","  \n","  * `ModelCheckpoint` - continually save the model during training"]},{"cell_type":"code","metadata":{"id":"8fsW06NDiA-v"},"source":["from tensorflow.keras import callbacks\n","\n","callbacks_list = [callbacks.EarlyStopping(monitor='acc', \n","                                          patience=1),\n","                  callbacks.ModelCheckpoint(filepath='my_model.h5', \n","                                            monitor='val_loss', \n","                                            save_best_only=True)]\n","\n","model.compile(...)\n","\n","model.fit(x, y,\n","          epochs=10,\n","          batch_size=32,\n","          callbacks=callbacks_list,\n","          validation_data=(x_val, y_val))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y2qCjHl6ieXZ"},"source":["* **ReduceLROnPlateau** callback\n","\n","  * `ReduceLROnPlateau` - reduce the learning rate when the validation loss has stopped improving"]},{"cell_type":"code","metadata":{"id":"EMguoT2Cit6_"},"source":["callbacks_list = [callbacks.ReduceLROnPlateau(monitor='val_loss',\n","                                              factor=0.1,\n","                                              patience=10)]\n","\n","model.compile(...)\n","\n","model.fit(x, y,\n","          epochs=10,\n","          batch_size=32,\n","          callbacks=callbacks_list,\n","          validation_data=(x_val, y_val))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dKN5dR4vjOWS"},"source":["* Writing your own callback\n","\n","  * Callbacks are implemented by subclassing the class `keras.callbacks.Callback`.\n","  \n","  * You can then implement any number of the named methods, which are called at various points during training.\n","    * `on_epoch_begin` and `on_epoch_end`\n","    * `on_batch_begin` and `on_batch_end`\n","    * `on_train_begin` and `on_train_end`\n","\n","  * Additionally, the callback has access to the following attributes.\n","    * `self.model` - the model instance \n","    * `self.validation_data` - what was passed to `fit` as validation data\n","    \n","  * Example: a custom callback that saves to disk the activations of every layer of the model at the end of every epoch, computed on the first sample of the validation set."]},{"cell_type":"code","metadata":{"id":"y2YQQc9kkQ_u"},"source":["from tensorflow.keras import callbacks, models\n","import numpy as np\n","\n","class ActivationLogger(callbacks.Callback):\n","  \n","  def set_model(self, model):\n","    self.model = model\n","    layer_outputs = [layer.output for layer in model.layers]\n","    self.activations_model = models.Model(model.input, layer_outputs)\n","    \n","  def on_epoch_end(self, epoch, logs=None):\n","    if self.validation_data is None:\n","      raise RuntimeError('Requires validation_data.')\n","    validation_sample = self.validation_data[0][0:1]\n","    activations = self.activations_model.predict(validation_sample)\n","    with open('activations_at_epoch' + str(epoch) + '.npz', 'w') as f:\n","      np.savez(f, activations)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sYvlVjEGmOmx"},"source":["### TensorBoard: the Tensorflow visualization framework"]},{"cell_type":"markdown","metadata":{"id":"Dk1Qaf22mUuk"},"source":["* Keep in mind that you need frequent feedback about what's going on inside your models during your experiments to develop good models.\n","\n","* TensorBoard is a browser-based visualization tool that comes packaged with Tensorflow.\n","  * It helps you visually monitor everything that goes on inside your model during training.\n","    * Visually monitoring metrics during training\n","    * Visualizing the model architecture\n","    * Visualizing histograms of activations and gradients\n","    * Exploring embeddings in 3D\n","    \n","* Using Tensorboard in Colab environment\n","  * Refer to https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks"]},{"cell_type":"code","metadata":{"id":"ffeJBY0OQw95","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651797293616,"user_tz":-540,"elapsed":47041,"user":{"displayName":"Sangheum Hwang","userId":"12292317320178717925"}},"outputId":"00f60f23-ee28-4af0-8680-294183e9103e"},"source":["# mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# make log directory\n","import os\n","log_dir = '/content/gdrive/My Drive/exp/logs/imdb_trial_03'\n","\n","if not os.path.exists(log_dir):\n","  os.makedirs(log_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"inBpgGvTMLYP"},"source":["%load_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6c4BJvWrMMCs"},"source":["%tensorboard --logdir /content/gdrive/My\\ Drive/exp/logs/imdb_trial_03"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IJqDz5yZnM8e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651797405861,"user_tz":-540,"elapsed":89605,"user":{"displayName":"Sangheum Hwang","userId":"12292317320178717925"}},"outputId":"92f78dfe-ca0d-46c7-85e8-d26b0d4f220d"},"source":["import datetime\n","\n","from tensorflow.keras import models \n","from tensorflow.keras import layers \n","from tensorflow.keras import callbacks\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.datasets import imdb \n","from tensorflow.keras.preprocessing import sequence\n","\n","max_features = 10000\n","max_len = 500\n","\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features) \n","x_train = sequence.pad_sequences(x_train, maxlen=max_len) \n","x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n","\n","model = models.Sequential() \n","model.add(layers.Embedding(max_features, 128, \n","                           input_length=max_len,\n","                           name='embed'))\n","model.add(layers.Conv1D(32, 7, activation='relu')) \n","model.add(layers.MaxPooling1D(5)) \n","model.add(layers.Conv1D(32, 7, activation='relu')) \n","model.add(layers.GlobalMaxPooling1D()) \n","model.add(layers.Dense(1, activation='sigmoid')) \n","model.summary() \n","model.compile(optimizer=optimizers.RMSprop(lr=1e-4), \n","              loss='binary_crossentropy', \n","              metrics=['acc'])\n","\n","callbacks = [callbacks.TensorBoard(log_dir, histogram_freq=1)]\n","\n","history = model.fit(x_train, y_train,\n","                    epochs=20,\n","                    batch_size=128,\n","                    validation_split=0.2,\n","                    callbacks=callbacks)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17465344/17464789 [==============================] - 0s 0us/step\n","17473536/17464789 [==============================] - 0s 0us/step\n","Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embed (Embedding)           (None, 500, 128)          1280000   \n","                                                                 \n"," conv1d_5 (Conv1D)           (None, 494, 32)           28704     \n","                                                                 \n"," max_pooling1d_2 (MaxPooling  (None, 98, 32)           0         \n"," 1D)                                                             \n","                                                                 \n"," conv1d_6 (Conv1D)           (None, 92, 32)            7200      \n","                                                                 \n"," global_max_pooling1d_1 (Glo  (None, 32)               0         \n"," balMaxPooling1D)                                                \n","                                                                 \n"," dense_9 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 1,315,937\n","Trainable params: 1,315,937\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","157/157 [==============================] - 12s 26ms/step - loss: 0.6917 - acc: 0.5448 - val_loss: 0.6907 - val_acc: 0.4976\n","Epoch 2/20\n","157/157 [==============================] - 3s 22ms/step - loss: 0.6829 - acc: 0.6836 - val_loss: 0.6802 - val_acc: 0.6696\n","Epoch 3/20\n","157/157 [==============================] - 4s 22ms/step - loss: 0.6591 - acc: 0.7625 - val_loss: 0.6382 - val_acc: 0.7634\n","Epoch 4/20\n","157/157 [==============================] - 3s 22ms/step - loss: 0.5857 - acc: 0.7993 - val_loss: 0.5341 - val_acc: 0.8072\n","Epoch 5/20\n","157/157 [==============================] - 3s 22ms/step - loss: 0.4618 - acc: 0.8383 - val_loss: 0.4189 - val_acc: 0.8328\n","Epoch 6/20\n","157/157 [==============================] - 4s 22ms/step - loss: 0.3601 - acc: 0.8638 - val_loss: 0.3573 - val_acc: 0.8536\n","Epoch 7/20\n","157/157 [==============================] - 3s 22ms/step - loss: 0.3045 - acc: 0.8826 - val_loss: 0.3335 - val_acc: 0.8566\n","Epoch 8/20\n","157/157 [==============================] - 3s 22ms/step - loss: 0.2702 - acc: 0.8946 - val_loss: 0.3188 - val_acc: 0.8670\n","Epoch 9/20\n","157/157 [==============================] - 4s 22ms/step - loss: 0.2448 - acc: 0.9051 - val_loss: 0.3242 - val_acc: 0.8620\n","Epoch 10/20\n","157/157 [==============================] - 3s 22ms/step - loss: 0.2248 - acc: 0.9155 - val_loss: 0.3106 - val_acc: 0.8690\n","Epoch 11/20\n","157/157 [==============================] - 3s 22ms/step - loss: 0.2080 - acc: 0.9225 - val_loss: 0.3112 - val_acc: 0.8698\n","Epoch 12/20\n","157/157 [==============================] - 3s 22ms/step - loss: 0.1932 - acc: 0.9295 - val_loss: 0.3161 - val_acc: 0.8684\n","Epoch 13/20\n","157/157 [==============================] - 3s 22ms/step - loss: 0.1801 - acc: 0.9359 - val_loss: 0.3143 - val_acc: 0.8690\n","Epoch 14/20\n","157/157 [==============================] - 4s 22ms/step - loss: 0.1681 - acc: 0.9405 - val_loss: 0.3255 - val_acc: 0.8668\n","Epoch 15/20\n","157/157 [==============================] - 3s 22ms/step - loss: 0.1570 - acc: 0.9449 - val_loss: 0.3226 - val_acc: 0.8698\n","Epoch 16/20\n","157/157 [==============================] - 3s 22ms/step - loss: 0.1471 - acc: 0.9493 - val_loss: 0.3289 - val_acc: 0.8682\n","Epoch 17/20\n","157/157 [==============================] - 3s 22ms/step - loss: 0.1385 - acc: 0.9528 - val_loss: 0.3387 - val_acc: 0.8678\n","Epoch 18/20\n","157/157 [==============================] - 3s 22ms/step - loss: 0.1306 - acc: 0.9564 - val_loss: 0.3476 - val_acc: 0.8672\n","Epoch 19/20\n","157/157 [==============================] - 3s 22ms/step - loss: 0.1225 - acc: 0.9600 - val_loss: 0.3632 - val_acc: 0.8640\n","Epoch 20/20\n","157/157 [==============================] - 3s 22ms/step - loss: 0.1159 - acc: 0.9628 - val_loss: 0.3522 - val_acc: 0.8660\n"]}]},{"cell_type":"markdown","metadata":{"id":"FofdnfohPo5i"},"source":["## 7.3 Getting the most out of your models"]},{"cell_type":"markdown","metadata":{"id":"VOcJIkySPsH1"},"source":["### Advanced architecture patterns"]},{"cell_type":"markdown","metadata":{"id":"hO0onULpPwtV"},"source":["* **Batch normalization**(layer 중간중간에 표준화시키는 작업을 시행해보자)\n","\n","  * We have seen that the data normalization should be done before feeding the data into a network.\n","  \n","    ```python\n","    normalized_data = (data - np.mean(data, axis=...)) / np.std(data, axis=...)\n","    ```\n","  \n","  * But data normalization should be a concern after every transformation operated by the network.\n","  \n","  * It is a type of layer introduced in 2015 by Ioffe and Szegedy.\n","  \n","      <img src=\"https://drive.google.com/uc?id=1BZw_m1lVnfTaNK7blmmvzSgw1svwMXNN\" width=\"700\">\n","  \n","      <img src=\"https://drive.google.com/uc?id=1BVRTwGj3mNzdMOnKOG6_dd-gYn6Qoem2\" width=\"900\">\n","    \n","  * Why does it have learnable scale and shift parameters?\n","  \n","    <img src=\"https://drive.google.com/uc?id=1BfD-Cm7NIvh_MwoML0E0BDzx88RORVJX\" width=\"700\">\n","  "]},{"cell_type":"markdown","source":["여기서 batch normalization을 하는 이유가 뭘까?<br>\n","dense layer의 기준으로 생각을 해보면 우리는 어떤 layer에 activation을 거치고 어떠한 결과값을 낼것이다. 근데 이렇게 나온 결과값들이 어떠한 모양이나 분포를 이루고 있다고 ㅅ애각을 하자.<br>\n","이러면 그 분포를 만들기 위한 여러개의 paramter가 미세하게 조정이 될것이다.<br>\n","그렇게 어렵게 가지말고 0이 평균인 작은 분포를 만든뒤에 그걸 가지고 늘리고 줄이고 하는게 훨씬 쉽다.<br>\n","는 이야기이다."],"metadata":{"id":"bA8Mls8MUtlz"}},{"cell_type":"code","metadata":{"id":"5bY7VoUeZzoB"},"source":["# Option 1\n","conv_model.add(layers.Conv2D(32, 3, activation='relu')) \n","conv_model.add(layers.BatchNormalization())\n","\n","dense_model.add(layers.Dense(32, activation='relu')) \n","dense_model.add(layers.BatchNormalization())\n","\n","# Option 2\n","conv_model.add(layers.Conv2D(32, 3)) \n","conv_model.add(layers.BatchNormalization())\n","conv_model.add(layers.Activation('relu'))\n","\n","dense_model.add(layers.Dense(32)) \n","dense_model.add(layers.BatchNormalization())\n","dense_model.add(layers.Activation('relu'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Micqpt6ObbOU"},"source":["### Hyperparameter optimization"]},{"cell_type":"markdown","metadata":{"id":"KaM00mEFcIUi"},"source":["* When building a deep learning model, you have to make many decisions:\n","  * How many layers?\n","  * How many units or filters?\n","  * Which activation?\n","  * And many more.\n","  \n","* These architecture-level parameters are called *hyperparameters*.\n","\n","* We need to explore the space of possible decisions automatically, systematically, in a principled way.\n","\n","* The process of optimizing hyperparameters:\n","  * Choose a set of hyperparameters.\n","  * Build the corresponding model.\n","  * Fit it to your training data, and measure the final performance on the validation data.\n","  * Choose the next set of hyperparameters to try.\n","  * Repeat.\n","  * Eventually, measure performance on the test data.\n","  \n","* It is known that random search is the best solution, despite being the most naive one."]},{"cell_type":"markdown","metadata":{"id":"lu6J_DvUdnrt"},"source":["### Model ensembling"]},{"cell_type":"markdown","metadata":{"id":"22vjuqnodqF8"},"source":["* Ensembling consists of pooling together the predictions of a set of different models, to produce better predictions.\n","\n","* It relies on the assumption that different good models trained independently are likely to be good for different reasons.\n","\n","* The easiest way to pool the predictions of a set of classifiers is to average their predictions at inference time.\n","\n","  ```python\n","  preds_a = model_a.predict(x_val)\n","  preds_b = model_b.predict(x_val)\n","  preds_c = model_c.predict(x_val)\n","  preds_d = model_d.predict(x_val)\n","  \n","  final_preds = 0.25 * (preds_a + preds_b + preds_c + preds_d)\n","  ```\n","  \n","* Or if you know which classifier is better, you can use a weighted average.\n","\n","  ```python\n","  preds_a = model_a.predict(x_val)\n","  preds_b = model_b.predict(x_val)\n","  preds_c = model_c.predict(x_val)\n","  preds_d = model_d.predict(x_val)\n","  \n","  final_preds = w_a * preds_a + w_b * preds_b + w_c * preds_c + w_d * preds_d\n","  ```\n","  \n","* The key to making ensembling work is the diversity of the set of classifiers.\n","  * Emsenble models should be as good as possible while being as different as possible.\n","  * Use very different architectures or even different ML approaches."]},{"cell_type":"code","metadata":{"id":"YSB8CraDfZsj"},"source":[""],"execution_count":null,"outputs":[]}]}